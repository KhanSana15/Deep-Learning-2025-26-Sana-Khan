{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPTZ9AN0a8ycZQpF3Td1D3k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhanSana15/Deep-Learning-2025-26-Sana-Khan/blob/main/Sana_IBM_Sem3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DATA PREPROCESSING**"
      ],
      "metadata": {
        "id": "aYDrHF8tFilT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJcMSTWTApVT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset= pd.read_csv(\"/content/MyDataset.csv\")"
      ],
      "metadata": {
        "id": "TutHqAYpBp4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "MIR0elpJCDnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "id": "kOYA15hmCF5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_data=dataset.isnull()"
      ],
      "metadata": {
        "id": "AVY8RRrIDyOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_data.head()"
      ],
      "metadata": {
        "id": "dO3e2e89D_fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['AGE'].fillna(dataset['AGE'].mean(), inplace=True)\n",
        "dataset"
      ],
      "metadata": {
        "id": "63hSmQ_JENFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['GENDER'].fillna(dataset['GENDER'].mode()[0], inplace=True)\n",
        "dataset"
      ],
      "metadata": {
        "id": "l2Z2Ha3eLdzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.loc[2, 'INCOME'] = 5000\n",
        "dataset"
      ],
      "metadata": {
        "id": "FFCWpg_kUb3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.loc[2, 'GENDER'] = 'M'\n",
        "dataset.loc[1, 'HOMETOWN'] = 'Varanasi'\n",
        "dataset"
      ],
      "metadata": {
        "id": "IBaDXOl4Qh-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#feature scaling\n",
        "dataset['INCOME']= (dataset['INCOME']-dataset['INCOME'].min())/(dataset['INCOME'].max()-dataset['INCOME'].min())\n",
        "dataset"
      ],
      "metadata": {
        "id": "j5q0am2PQ37m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **NEW**\n"
      ],
      "metadata": {
        "id": "O3VrUa4xhb18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'Employee_ID': [101, 102, 103, 104, 105, 106, 107, 108],\n",
        "    'Age': [25.0, 32.0, np.nan, 45.0, 22.0, 51.0, 38.0, 29.0],\n",
        "    'Department': ['Sales', 'IT', 'HR', 'Sales', 'IT', 'Finance', np.nan, 'HR'],\n",
        "    'Experience_Years': [2, 10, 5, 20, 1, 25, 12, 4],\n",
        "    'Gender': ['F', 'M', 'M', 'F', 'M', 'F', np.nan, 'M'],\n",
        "    'Salary': [50000, 90000, 60000, 130000, 45000, 150000, 100000, 55000],\n",
        "    'Promoted': ['No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'No']\n",
        "}"
      ],
      "metadata": {
        "id": "tjFmjca0XMd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "lMqCkbRrg9rI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new= new.DataFrame(data)"
      ],
      "metadata": {
        "id": "TIzXSWm6hwOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new.isnull()"
      ],
      "metadata": {
        "id": "N1ejdcMJhA2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LINEAR REGRESSION**"
      ],
      "metadata": {
        "id": "5evrjf3v9RWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "DB2RmfGa9Zlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create simple dataset manually\n",
        "\n",
        "dataset= {\n",
        "    'sqft_living': [650, 800, 1000, 1200, 1400, ],\n",
        "    'price': [9000, 120000, 150000, 170000, 190000]\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "la6KeH-N-Ge3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert to DataFrame\n",
        "home_data= pd.DataFrame(dataset)\n",
        "\n",
        "print(\"Sample dataset created successfully!\")\n",
        "print(home_data)"
      ],
      "metadata": {
        "id": "-EGxF-ab_VK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare feature (x) and target (y)\n",
        "\n",
        "x= home_data[['sqft_living']].values   # Feature must be 2D\n",
        "y= home_data[['price']].values         #Target 1D"
      ],
      "metadata": {
        "id": "yoWv2oZb_xwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the dataset into training and testing\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=1/3, random_state=0)"
      ],
      "metadata": {
        "id": "-0L_9odNAQLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the simple linear linear regression to the training dataset\n",
        "from sklearn.linear_model import LinearRegression\n",
        "sana= LinearRegression()\n",
        "sana.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "MQ_f9lTOBXVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict of test and training set results\n",
        "\n",
        "y_test_pred= sana.predict(x_test)\n",
        "y_train_pred= sana.predict(x_train)"
      ],
      "metadata": {
        "id": "Vc68mC08B5hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print model parameters and simple metrics\n",
        "\n",
        "print(\"\\n Model slope (coefficient): \", sana.coef_[0])\n",
        "print(\"\\n Model intercept (coefficient): \", sana.intercept_)\n",
        "\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "print(\"\\nTrain R^2: \", r2_score(y_train, y_train_pred))\n",
        "print(\"\\nTest R^2: \", r2_score(y_test, y_test_pred))\n",
        "print(\"Test RMSE: \", np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
        "\n"
      ],
      "metadata": {
        "id": "hge0B8dOCKhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize the training results with a smooth regression line\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.scatter(x_train, y_train, label='Training Data', color='green')"
      ],
      "metadata": {
        "id": "MHOX-8s5DAYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a smooth line for regression\n",
        "\n",
        "line_x= np.linspace(x.min(), x.max(), 100).reshape(-4,1)\n",
        "line_y= sana.predict(line_x)\n",
        "plt.plot(line_x, line_y, label='Regression Line', color='pink', linewidth=2)\n"
      ],
      "metadata": {
        "id": "0C1UDloiEJt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a smooth line for regression\n",
        "\n",
        "line_x= np.linspace(x.min(), x.max(), 100).reshape(-4,1)\n",
        "line_y= sana.predict(line_x)\n",
        "plt.plot(line_x, line_y, label='Regression Line', color='skyblue', linewidth=2)\n",
        "\n",
        "\n",
        "plt.title('House Price vs Living Area (Training Set)')\n",
        "plt.xlabel('Living Area (sqft)')\n",
        "plt.ylabel('House Price ($)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DDKu2O24E6XV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize the test results with a smooth regression line\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.scatter(x_test, y_test, label='Test Data', color='green')\n",
        "\n",
        "plt.title('House Price vs Living Area (Test Set)')\n",
        "plt.xlabel('Living Area (sqft)')\n",
        "plt.ylabel('House Price ($)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8Jq8ppUzF8h0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "noasxWc3Gpdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LOGISTIC REGRESSION**"
      ],
      "metadata": {
        "id": "e5b3A-KGKrOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "mfQzvgLYK4H7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LOAD DATASET\n",
        "\n",
        "titanic= pd.read_csv('/content/Titanic-Dataset.csv')\n",
        "\n",
        "print(titanic.info())\n",
        "print(titanic.describe())"
      ],
      "metadata": {
        "id": "n-OhDofMLe85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features= ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']\n",
        "titanic= titanic[features+ ['Survived']]\n",
        "\n",
        "titanic"
      ],
      "metadata": {
        "id": "0UisAFS_NJr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling missing values\n",
        "# Fill missing 'Age' values with the median of the 'Age' column\n",
        "titanic['Age'].fillna(titanic['Age'].median(), inplace=True)"
      ],
      "metadata": {
        "id": "V__fRNtTOkfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert categorical column 'Sex' to numerical\n",
        "le = LabelEncoder()\n",
        "#Fit and transform the 'Sex' column: Male = 1, Female = 0\n",
        "titanic['Sex'] = le.fit_transform(titanic['Sex']) # Male=1, Female=0"
      ],
      "metadata": {
        "id": "WbOMUKP3Qfm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split featues and target\n",
        "x = titanic[features]\n",
        "y = titanic['Survived']\n",
        "\n",
        "# Train-Test split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "Loayk9lWQn0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train logistic regression\n",
        "from sklearn.linear_model import LogisticRegression # Already imported at the top\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "M0TaqvGtQyAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Evaluation\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "eKVig15mQ7H9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "Vx2tD5J8RBVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix Visualization\n",
        "import matplotlib.pyplot as plt # Already imported at the top\n",
        "import seaborn as sns # Already imported at the top\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Did Not Survive', 'Survived'],\n",
        "            yticklabels=['Did Not Survive', 'Survived'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4Y9McgS-RMI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SELF PRACTICE**"
      ],
      "metadata": {
        "id": "n8s-rqcJnFdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "6__0yz3ynRHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cancer= pd.read_csv(\"/content/healthcare_dataset.csv\")\n",
        "cancer"
      ],
      "metadata": {
        "id": "Mr-2gAqanz3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cancer.head()"
      ],
      "metadata": {
        "id": "b1bP38-joBoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missingdata= cancer.isnull()\n",
        "missingdata.head()"
      ],
      "metadata": {
        "id": "MznZYtgRoDnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOGISTIC REGRESSION (CANCER PREDICTION- Y/N)"
      ],
      "metadata": {
        "id": "Q-tRdbu1pcXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "ko5qNUc8oc_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cancer= pd.read_csv(\"/content/healthcare_dataset.csv\")\n",
        "cancer"
      ],
      "metadata": {
        "id": "hVH297UnDPVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features= ['Age', 'Medications', 'Admission Type', 'Test Results', 'Blood Type', 'Fare']\n",
        "cancer= cancer[features+ ['Survived']]\n",
        "\n",
        "cancer"
      ],
      "metadata": {
        "id": "uwBzskhJDrS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DECISION TREE**"
      ],
      "metadata": {
        "id": "5UY8ZtK6E4N5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "MoYXiiHeFFIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create your own dataset\n",
        "\n",
        "data= {\n",
        "    'Study_Hours': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "    'Attendance (%)': [55, 60, 65, 70, 75, 80, 85, 90, 95, 98],\n",
        "    'Internal_Marks'  : [35, 45, 50, 55, 60, 70, 75, 80, 85, 90],\n",
        "    'Result': ['Fail', 'Fail', 'Fail', 'Fail', 'Pass', 'Pass', 'Pass', 'Pass', 'Pass', 'Pass']\n",
        "}"
      ],
      "metadata": {
        "id": "bfzdbXgJGzS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert to dataframe\n",
        "student= pd.DataFrame(data)\n",
        "student"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xm3IkTTfHr32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Show dataset\n",
        "print(\"Student Performance Dataset\")\n",
        "print(student)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "BjuGflIqH7Ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "busqfP_WINJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare data\n",
        "x= student[['Study_Hours', 'Attendance (%)', 'Internal_Marks']]\n",
        "y= student['Result']\n"
      ],
      "metadata": {
        "id": "xFVVY1r-IyI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split Data\n",
        "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "bgElDT8CJmjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train model\n",
        "sana= DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
        "sana.fit(x_train, y_train)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "NQqhwjaIKSDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict\n",
        "y_pred= sana.predict(x_test)"
      ],
      "metadata": {
        "id": "9HozvEQBK3PK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate\n",
        "print(\"\\n Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\n Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7zDY_Mx-LWXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RANDOM FOREST**"
      ],
      "metadata": {
        "id": "Sj39ABlYNTLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 1: IMPORTING NECESSARY LIBRARIES\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "yGDkKeSzNXAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load the famous Iris dataset\n",
        "\n",
        "iris = load_iris()\n",
        "iris"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6x6a6YI1P2Lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 3: CREATE DATAFRAME FOR BETTER VISUALIZATION\n",
        "\n",
        "new= pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "new['species']= iris.target"
      ],
      "metadata": {
        "id": "ZK63otl6P73A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP4: DISP 5 ROWS\n",
        "print(\"Sample of Dataset: \")\n",
        "print(new.head())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "KbHh81gZQaIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 5: Split dtata into feature (X) and Lables (Y)\n",
        "x = new.iloc[:,:-1] #All columns except last one\n",
        "y = new.iloc[:,-1] #Only Last column \"Species\""
      ],
      "metadata": {
        "id": "fxQTXj9nQoeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SPLIT DATA INTO TRAIN TEST\n",
        "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "yVVbrb7tWQGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CREATE A MODEL\n",
        "sana= RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "sana.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "3gl5C5-0WPbS",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 9: PREDICT USING THE TEST DATA\n",
        "y_pred= sana.predict(x_test)"
      ],
      "metadata": {
        "id": "ukcd6OhsSENp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 10: EVALUATE MODEL PERFORMANCE\n",
        "print(\"\\n Confusion_Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"\\n Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"\\n Accuracy of Random Forest model:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "N6IdhQQBSSXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rn."
      ],
      "metadata": {
        "id": "7D5nNlWYwul1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **K- NEAREST NEIGHBOUR (KNN)**"
      ],
      "metadata": {
        "id": "Gcw1JFI7V9ud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "8Bf8uHpcWCRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris = load_iris()"
      ],
      "metadata": {
        "id": "4Jc0nDtqZ0Nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['species']= iris.target"
      ],
      "metadata": {
        "id": "Vu4uiMBYZ2an"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sample of Dataset: \")\n",
        "print(df.head())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "tgrLlErkZ5xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 5: Split dtata into feature (X) and Lables (Y)\n",
        "x = df.iloc[:,:-1] #All columns except \"Species\"\n",
        "y = df.iloc[:,-1] #Only \"Species\" column"
      ],
      "metadata": {
        "id": "AdJOQBrZaMvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 6: SPLIT IN TRAINING AND TESTING\n",
        "x_train, x_test, y_train, y_test, = train_test_split(x, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "gXfCL3aCamFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 7: FEATURE SCALING (IMP FOR KNN)\n",
        "\n",
        "scaler= StandardScaler()\n",
        "x_train= scaler.fit_transform(x_train)\n",
        "x_test= scaler.transform(x_test)"
      ],
      "metadata": {
        "id": "gqsN8Y6Xa_M8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 8: CREATE AND TRAIN KNN CLASSIFIER\n",
        "knn= KNeighborsClassifier(n_neighbors=5)    #k=5\n",
        "knn.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "yiLEV2QsbJdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 9: MAKE PREDICTIONS\n",
        "y_pred= knn.predict(x_test)"
      ],
      "metadata": {
        "id": "k8BktTS0baWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 10: EVALUATE MODEL PERFORMANCE\n",
        "print(\"\\n Confusion_Matrix:\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"\\nClassification Report: \", classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"\\n Accuracy of Random Forest model:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "1emeNRmkbiQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **POLYNOMIAL REGRESSION**"
      ],
      "metadata": {
        "id": "e2oe1Evigr0l"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M-G75siFg10X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BAGGING**"
      ],
      "metadata": {
        "id": "sp8VGwRirUBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP: 1 LIBRARIES\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
      ],
      "metadata": {
        "id": "2mPIU3jdrWvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 2: LOAD DATASET\n",
        "iris= load_iris()\n",
        "x, y = iris.data, iris.target"
      ],
      "metadata": {
        "id": "ZAoDZbQHtBa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 3: SPLIT TEST/TRAIN\n",
        "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.3, random_state=42)\n"
      ],
      "metadata": {
        "id": "Wm6DnZijsSxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 4: CREATE BASE MODEL\n",
        "base_model= DecisionTreeClassifier()\n"
      ],
      "metadata": {
        "id": "n5w7VMEcsoPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 5: create bagging model\n",
        "bag_model= BaggingClassifier(estimator=base_model, n_estimators=10, random_state=42)"
      ],
      "metadata": {
        "id": "CZGjQR3Mtl0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 6: TRAIN BOTH MODELS\n",
        "base_model.fit(x_train, y_train)\n",
        "bag_model.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "zCbf1Tvbt3Vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 7: COMPARE PERFORMANCE\n",
        "y_pred_base= base_model.predict(x_test)\n",
        "y_pred_bag= bag_model.predict(x_test)\n",
        "\n",
        "print(\"\\n Accuracy of single Decision Trees:\", accuracy_score(y_test, y_pred_base))\n",
        "print(\"Accuracy after Bagging:\", accuracy_score(y_test, y_pred_bag))\n"
      ],
      "metadata": {
        "id": "mf-5x2f-uM8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ofTFPJ22u_GH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **STACKING**"
      ],
      "metadata": {
        "id": "vf6NeL35wj_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "T7vQf50zwofq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 2: LOAD DATASET\n",
        "iris= load_iris()\n",
        "x, y = iris.data, iris.target"
      ],
      "metadata": {
        "id": "FoXUedm9M-2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "7aaIjWeYNYcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DEFINE BASE LEARNER\n",
        "base_learners= [\n",
        "    ('svm', SVC(probability=True)),\n",
        "    ('knn', KNeighborsClassifier(n_neighbors=5))\n",
        "]"
      ],
      "metadata": {
        "id": "_HjdzPsCxAuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#META LEARNER (FINAL MODEL)\n",
        "meta_model= LogisticRegression()"
      ],
      "metadata": {
        "id": "KZuGFq2Xxcxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CREATE STACKING MODEL\n",
        "stack_model= StackingClassifier(estimators=base_learners, final_estimator=meta_model)"
      ],
      "metadata": {
        "id": "iKkkiM6CxidA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TRAIN\n",
        "stack_model.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "QGV4dn82x5Oq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#EVALUATE\n",
        "y_pred= stack_model.predict(x_test)\n",
        "print(\"Accuracy with stacking: \", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "2tb-WzbryM0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ch7D9KtNyZ7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BOOSTING**"
      ],
      "metadata": {
        "id": "3xBOcHPxGKDQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AdaBoost:**"
      ],
      "metadata": {
        "id": "pwOGSPIBHPj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "CD7zrbejI8jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CREATE BASE MODEL (WEAK LEARNER)\n",
        "base_model= DecisionTreeClassifier(max_depth=1)"
      ],
      "metadata": {
        "id": "g7b5QJV0JLiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CREATE BOOSTNG MODEL\n",
        "boost_model= AdaBoostClassifier(estimator=base_model, n_estimators=50, learning_rate=1.0, random_state=42)"
      ],
      "metadata": {
        "id": "9mgEe72eJQ3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TRAIN\n",
        "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.3, random_state=42)\n",
        "boost_model.fit(x_train, y_train)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "EOU14maBJymg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#EVALUATE\n",
        "y_pred_boost= boost_model.predict(x_test)\n",
        "print(\"Accuracy with AdaBoost:\", accuracy_score(y_test, y_pred_boost))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "bbfPj8s_K219"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GRADIENT BOOST**"
      ],
      "metadata": {
        "id": "YvbwLOYFOqp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 1: IMPORT\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "UawZVeB0OvPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 2: LOAD DATASET\n",
        "iris= load_iris()\n",
        "x,y = iris.data, iris.target"
      ],
      "metadata": {
        "id": "BdNjuHsePSPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 3: SPLIT INTO TRAIN AND TESTS SETS\n",
        "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "bxdRQ2wRPcsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 4: CREATE GRADIENT BOOSTING MODEL\n",
        "gb_model= GradientBoostingClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=3,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "x0zMThxJQcB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 5: TRAIN (FIT) THE MODEL\n",
        "gb_model.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "Mj8GJ5JFRqWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 6: MAKE PREDICTIONS\n",
        "y_pred = gb_model.predict(x_test)"
      ],
      "metadata": {
        "id": "6nqOE9BwR3GF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 7: EVALUATE PERFORMANCE\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"\\nAccuracy of gradient boosting model:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4ylD8-qBSGej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**XGBOOST**"
      ],
      "metadata": {
        "id": "ZMh2GvhuTVtw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 1: INSTALL AND IMPORT LIBRARIES\n",
        "!pip install xgboost\n",
        "\n",
        "import xgboost as xgb\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "nGp40AdNTbQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP2: LOAD DATASET\n",
        "iris= load_iris()\n",
        "x, y = iris.data, iris.target"
      ],
      "metadata": {
        "id": "P8m6m1JXUJDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SPLIT 3: SPLIT DATA\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "bkkmfCWDUYSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 4: CREATE XGBOOST MODEL\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    n_estimators=100,                #number of trees\n",
        "    learning_rate=0.1,               #step size shrinkage\n",
        "    max_depth=3,                     #maximum depth of machine\n",
        "    subsample=0.8,                   #\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42,\n",
        "    eval_metric='mlogloss'\n",
        ")\n"
      ],
      "metadata": {
        "id": "m2Tb2bIyUlXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Train (fit) the model\n",
        "xgb_model.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "EERMHuO8VMa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Make predictions\n",
        "y_pred = xgb_model.predict(x_test)"
      ],
      "metadata": {
        "id": "OJSabMmnMi-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # Step 7: Evaluate performance\n",
        "  print(\"Confusion Matrix:\")\n",
        "  print(confusion_matrix(y_test, y_pred))\n",
        "  print(\"\\nClassification Report:\")\n",
        "  print(classification_report(y_test, y_pred))\n",
        "  print(\"\\nAccuracy of XGBoost model:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "emDe6Ke3M9ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SVM**"
      ],
      "metadata": {
        "id": "40aWGozENEEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import Libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "niuJKHXoNJLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load dataset (Iris)\n",
        "iris = datasets.load_iris()\n",
        "x = iris.data[:, :2]  # Take first two features for easy 2D visualization\n",
        "y = iris.target"
      ],
      "metadata": {
        "id": "VpHfvD-dNi6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Split data\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "g177NTiXNkkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Train SVM model\n",
        "model = SVC(kernel='linear')  # Linear SVM\n",
        "model.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "F4gyC8Z7NmKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Predict and check accuracy\n",
        "y_pred = model.predict(x_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "WYQGhJN5NtxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Visualize decision boundaries\n",
        "x_min, x_max = x[:, 0].min() - 1, x[:, 0].max() + 1\n",
        "y_min, y_max = x[:, 1].min() - 1, x[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
        "                     np.arange(y_min, y_max, 0.02))\n",
        "\n",
        "Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "plt.contourf(xx, yy, Z, alpha=0.3)\n",
        "plt.scatter(x[:, 0], x[:, 1], c=y, edgecolors='k', marker='o')\n",
        "plt.xlabel('Sepal length')\n",
        "plt.ylabel('Sepal width')\n",
        "plt.title('SVM Decision Boundary (Linear Kernel)')\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "weHTl8e6Nw-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DEEP LEARNING**"
      ],
      "metadata": {
        "id": "8QF5cngoZhbS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tenser Flow and Keras**"
      ],
      "metadata": {
        "id": "FEEJfdLjZo3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "nIWg8-rEZmc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 2: CREATE SIMPLE TRAINING DATA\n",
        "#features: [Study Hours, Sleep Hours]\n",
        "x= np.array([\n",
        "    [2,9],\n",
        "    [1,5],\n",
        "    [3,6],\n",
        "    [4,8],\n",
        "    [6,9],\n",
        "    [5,5],\n",
        "    [7,3]\n",
        "], dtype=float)\n",
        "\n",
        "#LABELS: 1= Pass, 0=Fail\n",
        "y= np.array([\n",
        "    [0],\n",
        "    [0],\n",
        "    [0],\n",
        "    [1],\n",
        "    [1],\n",
        "    [0],\n",
        "    [1]\n",
        "], dtype=float)"
      ],
      "metadata": {
        "id": "ywuxENbbaKfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 3: NORMALIZE DATA(important for neural networks)\n",
        "\n",
        "x= x/ np.amax(x, axis=0)   #Scale all values between 0 and 1"
      ],
      "metadata": {
        "id": "T1M9JnrMbHNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 4: BUILD THE NEURAL NETWORK MODEL\n",
        "\n",
        "model= keras.Sequential([\n",
        "    layers.Dense(4, input_dim=2, activation='relu'),        #Hidden layer with 4 neurons\n",
        "    layers.Dense(1, activation='sigmoid'),                  #Output layer  (binary output)\n",
        "])"
      ],
      "metadata": {
        "id": "8PCF-tZ6b5XZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 5: COMPILE THE MODEL\n",
        "model.compile(\n",
        "    optimizer='adam',                #optimization\n",
        "    loss='binary_crossentropy',      #Suitable for binary classification\n",
        "    metrics=['accuracy']             #To measure performance\n",
        ")"
      ],
      "metadata": {
        "id": "fkZcOmDmc3Z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 6: TRAIN THE MODEL\n",
        "\n",
        "model.fit(x, y, epochs=200, verbose=0)     #Train for 200 epoches quietly (quietly= cuz verbose/output is 0)"
      ],
      "metadata": {
        "id": "pRZATY9KenLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 7: TEST THE MODEL WITH A NEW INPUT\n",
        "test_data = np.array([[4,7]])/ np.amax(x, axis=0)       #normalize test input\n",
        "prediction = model.predict(test_data)\n",
        "print(\"Predicted Output (1=Pass, 0=Fail):\", prediction)\n",
        "if prediction >= 0.5:\n",
        "     print(\"The student is likely to PASS\")\n",
        "else:\n",
        "     print(\"The student is likely to FAIL\")"
      ],
      "metadata": {
        "id": "tEfILJZNfxcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PCA (Principle Component Analysis)**"
      ],
      "metadata": {
        "id": "hF8rOY3li1gl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**An unsupervised machine learning used for dimensionality reduction**\n",
        "\n",
        "**STEPS:**\n",
        "\n",
        "**STEP1:** Calculate mean.\n",
        "\n",
        "**STEP2:** Create co-varience matrix.\n",
        "\n",
        "**STEP3:** Calculate Eigen values.\n",
        "\n",
        "**STEP4:**"
      ],
      "metadata": {
        "id": "JT_KHaBJjuPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 1: IMPORT LIBRARIES\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.datasets import load_iris"
      ],
      "metadata": {
        "id": "3wJ9Zkno1N_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  #STEP 2: LOAD DATASET\n",
        "  iris= load_iris()\n",
        "  x= iris.data\n",
        "  y= iris.target"
      ],
      "metadata": {
        "id": "bd1GVi801hhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 3: APPLY PCA (reduce 4D-> 2D)\n",
        "pca= PCA(n_components=2)\n",
        "x_pca= pca.fit_transform(x)"
      ],
      "metadata": {
        "id": "oN2yPoif1mkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 4: VISUALIZE THE RESULTS\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.scatter(x_pca[:,0], x_pca[:,1], c=y, cmap='rainbow')\n",
        "plt.title('PCA of Iris Dataset(4 features-> 2 principal components)')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "TuAnxVIT13up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **K-MEANS CLUSTERING**"
      ],
      "metadata": {
        "id": "LUwfmXhjQ1YC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part of Unsupervised Learning.**\n",
        "\n",
        "E= root[(x1-x2)^2 + (y1-y2)^2]\n"
      ],
      "metadata": {
        "id": "I5GyT1UjRuIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 1: IMPORT LIBRARIES\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "id": "gAAwOS8PQ5R_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 2: CREATE SOME SAMPLE DATA\n",
        "x= np.array([\n",
        "    [1,2], [1.5,1.8], [5,8],\n",
        "    [8,8], [1,0.6], [9,11],\n",
        "    [8,2], [10,3], [9,3]\n",
        "])"
      ],
      "metadata": {
        "id": "fcNUKPI_eA_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 3: BUILD K-MEANS MODEL\n",
        "kmeans= KMeans(n_clusters=3, random_state=0)"
      ],
      "metadata": {
        "id": "VDP8aRLael5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 4: FIT THE MODEL\n",
        "kmeans.fit(x)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "MtxsU_BpfAH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 5: GET THE CLUSTER CENTERS AND LABELS\n",
        "centroids =kmeans.cluster_centers_\n",
        "labels= kmeans.labels_"
      ],
      "metadata": {
        "id": "tY_EnAnEfDod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 6: VISUALIZE THE CLUSTERS\n",
        "colors = [\"red\", \"green\", \"blue\"]\n",
        "\n",
        "for i in range(len(x)):\n",
        "      plt.scatter(x[i][0], x[i][1],\n",
        "color=colors[labels[i]])\n",
        "\n",
        "plt.scatter(centroids[:,0], centroids[:,1],\n",
        "marker='x', s=200, color='black')\n",
        "plt.title('K-Means Clustering')\n",
        "plt.xlabel('x-axis')\n",
        "plt.ylabel('y-axis')\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "eaPhxtWWfgoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **HIERARCHIAL CLUSTERING**"
      ],
      "metadata": {
        "id": "EtokU3qFf9qF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Agglomerative: bottom-top**\n",
        "\n",
        "**Divisive: top-bottom**\n",
        "\n"
      ],
      "metadata": {
        "id": "NK0elXg_hntK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 1: IMPORT LIBRARIES\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster"
      ],
      "metadata": {
        "id": "4tsukpynhjxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 2: CREATE SAMPLE DATA\n",
        "x= np.array([\n",
        "     [1,2], [1.5,1.8], [5,8],\n",
        "    [8,8], [1,0.6], [9,11],\n",
        "    [8,2], [10,3], [9,3]\n",
        "])"
      ],
      "metadata": {
        "id": "k2f9i2HBiO2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 3: PERFORM HIERARCHIAL CLUTERING\n",
        "z= linkage(x, method='ward')       #'ward' minimizes variance"
      ],
      "metadata": {
        "id": "xEaJxVcdigpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 4: PLOT THE DENDROGRAM\n",
        "plt.figure(figsize=(8,5))\n",
        "dendrogram(z)\n",
        "plt.title('Hierarchial Clustering Dendogram')\n",
        "plt.xlabel('Data Points')\n",
        "plt.ylabel('Distance')\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "M74p4TNni_Fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 5: FORM CLUSTERS (e.g. cut the dendrogram at a certain height)\n",
        "clusters = fcluster(z, t=3, criterion='maxclust')\n",
        "\n",
        "print(\"Cluster labels: \", clusters)"
      ],
      "metadata": {
        "id": "Qr0wLwcFjcNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nJtblJEokDoK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}